{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fe3c265",
   "metadata": {},
   "source": [
    "# 3. ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ì¬ ì‹œë„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ea706c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# ì…€ 1 : ê³µí†µ ë¼ì´ë¸ŒëŸ¬ë¦¬ + ê²½ë¡œ ë³€ìˆ˜\n",
    "# ====================================\n",
    "import os, re, warnings, torch, numpy as np\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# open_clip_torch\n",
    "import open_clip\n",
    "\n",
    "# ğŸ¤— Transformers\n",
    "from transformers import (\n",
    "    BlipProcessor, BlipForConditionalGeneration,\n",
    "    AutoTokenizer, AutoModelForSeq2SeqLM\n",
    ")\n",
    "\n",
    "from rapidfuzz import fuzz\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---------------- ê²½ë¡œ ë³€ìˆ˜ë§Œ ìˆ˜ì • ----------------\n",
    "BLIP_CKPT = r\"./blip_finetuned_model_less_data/checkpoint-1250\"\n",
    "IMG_DIR   = r\"./dataset/open_dataset/test_input_images\"\n",
    "TEST_CSV  = r\"./dataset/open_dataset/test.csv\"\n",
    "SUB_CSV   = r\"./dataset/open_dataset/sample_submission.csv\"\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"âœ… Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab6a1f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š ëª¨ë¸ë³„ íŒŒë¼ë¯¸í„°(M)\n",
      " â€¢ BLIP-VQA (Fine-tuned) :   247.4 M\n",
      " â€¢ OpenCLIP ViT-L/14     :   427.6 M\n",
      " â€¢ FLAN-T5 Small         :    77.0 M\n",
      "ğŸ”¢ Total : 752.0 M  (0.752 B)\n",
      "âœ… 3B ì œì•½ ì¶©ì¡± & ë¼ì´ì„ ìŠ¤ ìš”ê±´ OK\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# ì…€ 2 : BLIP-VQA, OpenCLIP, FLAN-T5 Small ë¡œë“œ\n",
    "#         + íŒŒë¼ë¯¸í„° ìë™ ì§‘ê³„\n",
    "# ====================================\n",
    "from collections import OrderedDict\n",
    "\n",
    "param_tbl, total_params = OrderedDict(), 0\n",
    "def _add_model(name, model):\n",
    "    global total_params\n",
    "    n = sum(p.numel() for p in model.parameters()) / 1_000_000  # Million\n",
    "    param_tbl[name] = n\n",
    "    total_params += n\n",
    "    return model\n",
    "\n",
    "# 1) BLIP VQA (Fine-tuned)\n",
    "proc_blip = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-capfilt-large\")\n",
    "blip_vqa  = _add_model(\n",
    "    \"BLIP-VQA (Fine-tuned)\",\n",
    "    BlipForConditionalGeneration.from_pretrained(BLIP_CKPT).to(DEVICE).eval()\n",
    ")\n",
    "\n",
    "# 2) OpenCLIP ViT-L/14  (Pretrained='openai')\n",
    "clip_model, _, clip_pre = open_clip.create_model_and_transforms(\n",
    "    \"ViT-L-14\", pretrained=\"openai\"\n",
    ")\n",
    "clip_model = _add_model(\n",
    "    \"OpenCLIP ViT-L/14\",\n",
    "    clip_model.to(DEVICE).eval()\n",
    ")\n",
    "clip_tokenizer = open_clip.get_tokenizer(\"ViT-L-14\")\n",
    "\n",
    "# 3) FLAN-T5 Small\n",
    "tok_t5 = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    "flan_t5 = _add_model(\n",
    "    \"FLAN-T5 Small\",\n",
    "    AutoModelForSeq2SeqLM.from_pretrained(\n",
    "        \"google/flan-t5-small\",\n",
    "        torch_dtype=torch.bfloat16\n",
    "    ).to(DEVICE).eval()\n",
    ")\n",
    "\n",
    "# -------- íŒŒë¼ë¯¸í„° ê²°ê³¼ ì¶œë ¥ --------\n",
    "print(\"\\nğŸ“Š ëª¨ë¸ë³„ íŒŒë¼ë¯¸í„°(M)\")\n",
    "for n, m in param_tbl.items():\n",
    "    print(f\" â€¢ {n:<22}: {m:>7.1f} M\")\n",
    "print(f\"ğŸ”¢ Total : {total_params:.1f} M  ({total_params/1_000:.3f} B)\")\n",
    "\n",
    "assert total_params < 3_000, \"âŒ 3B ì´ˆê³¼ â€” ëª¨ë¸ ì¶•ì†Œ í•„ìš”\"\n",
    "print(\"âœ… 3B ì œì•½ ì¶©ì¡± & ë¼ì´ì„ ìŠ¤ ìš”ê±´ OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6025cd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ì´ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤: 852ê°œ\n",
      "\n",
      "ğŸ“ˆ ì§ˆë¬¸ ìœ í˜•ë³„ ë¶„í¬:\n",
      "  WHAT_IS: 369ê°œ (43.3%)\n",
      "  WHAT_MIGHT: 167ê°œ (19.6%)\n",
      "  WHY: 104ê°œ (12.2%)\n",
      "  WHICH: 34ê°œ (4.0%)\n",
      "  WHERE: 3ê°œ (0.4%)\n",
      "  WHEN: 9ê°œ (1.1%)\n",
      "  HOW: 15ê°œ (1.8%)\n",
      "  CULTURAL: 46ê°œ (5.4%)\n",
      "\n",
      "ğŸ“ ì„ íƒì§€ í‰ê·  ê¸¸ì´: 8.6 ë‹¨ì–´\n",
      "ğŸ“ ì„ íƒì§€ ê¸¸ì´ ë²”ìœ„: 5 ~ 15 ë‹¨ì–´\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# ì…€ 3: ë°ì´í„°ì…‹ íŠ¹ì„± ë¶„ì„\n",
    "# ===============================\n",
    "\n",
    "df = pd.read_csv(TEST_CSV)\n",
    "print(f\"ğŸ“Š ì´ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤: {len(df)}ê°œ\")\n",
    "\n",
    "# ì§ˆë¬¸ ìœ í˜• ë¶„ì„\n",
    "question_types = {\n",
    "    'what_is': 0, 'what_might': 0, 'why': 0, 'which': 0, \n",
    "    'where': 0, 'when': 0, 'how': 0, 'cultural': 0\n",
    "}\n",
    "\n",
    "for question in df['Question']:\n",
    "    q_lower = question.lower()\n",
    "    if 'what is' in q_lower or 'what are' in q_lower:\n",
    "        question_types['what_is'] += 1\n",
    "    elif 'what might' in q_lower or 'what likely' in q_lower:\n",
    "        question_types['what_might'] += 1  \n",
    "    elif 'why' in q_lower:\n",
    "        question_types['why'] += 1\n",
    "    elif 'which' in q_lower:\n",
    "        question_types['which'] += 1\n",
    "    elif 'where' in q_lower:\n",
    "        question_types['where'] += 1\n",
    "    elif 'when' in q_lower or 'what time' in q_lower:\n",
    "        question_types['when'] += 1\n",
    "    elif 'how' in q_lower:\n",
    "        question_types['how'] += 1\n",
    "    elif 'cultural' in q_lower or 'tradition' in q_lower:\n",
    "        question_types['cultural'] += 1\n",
    "\n",
    "print(\"\\nğŸ“ˆ ì§ˆë¬¸ ìœ í˜•ë³„ ë¶„í¬:\")\n",
    "for qtype, count in question_types.items():\n",
    "    if count > 0:\n",
    "        print(f\"  {qtype.upper()}: {count}ê°œ ({count/len(df)*100:.1f}%)\")\n",
    "\n",
    "# ì„ íƒì§€ ê¸¸ì´ ë¶„ì„\n",
    "option_lengths = []\n",
    "for _, row in df.head(50).iterrows():  # ì²˜ìŒ 50ê°œë§Œ ë¶„ì„\n",
    "    for opt in ['A', 'B', 'C', 'D']:\n",
    "        option_lengths.append(len(row[opt].split()))\n",
    "\n",
    "print(f\"\\nğŸ“ ì„ íƒì§€ í‰ê·  ê¸¸ì´: {np.mean(option_lengths):.1f} ë‹¨ì–´\")\n",
    "print(f\"ğŸ“ ì„ íƒì§€ ê¸¸ì´ ë²”ìœ„: {min(option_lengths)} ~ {max(option_lengths)} ë‹¨ì–´\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d59ebee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì‚¼ì„± ì±Œë¦°ì§€ íŠ¹í™” ì ìˆ˜ í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ===============================  \n",
    "# ì…€ 4: ì‚¼ì„± ì±Œë¦°ì§€ íŠ¹í™” ì ìˆ˜ í•¨ìˆ˜\n",
    "# ===============================\n",
    "\n",
    "def clean(txt: str) -> str:\n",
    "    \"\"\"í…ìŠ¤íŠ¸ ì •ê·œí™” - í•œê¸€ í¬í•¨ ì²˜ë¦¬\"\"\"\n",
    "    txt = re.sub(r\"[^a-z0-9 ]\", \" \", txt.lower()).strip()\n",
    "    return re.sub(r\"\\s+\", \" \", txt)\n",
    "\n",
    "# ë‹¤ì¤‘ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (ì‚¼ì„± ì±Œë¦°ì§€ ì§ˆë¬¸ ìœ í˜•ë³„)\n",
    "PROMPT_TEMPLATES = {\n",
    "    'what_is': [\n",
    "        \"Question: {q} Answer: {o}\",\n",
    "        \"What do you see? {q} It is {o}\",\n",
    "        \"{q} The answer is {o}\"\n",
    "    ],\n",
    "    'what_might': [\n",
    "        \"Question: {q} Answer: {o}\",\n",
    "        \"What might happen? {q} Likely {o}\", \n",
    "        \"{q} Probably {o}\"\n",
    "    ],\n",
    "    'why': [\n",
    "        \"Question: {q} Answer: {o}\",\n",
    "        \"Why is this happening? {q} Because {o}\",\n",
    "        \"{q} The reason is {o}\"\n",
    "    ],\n",
    "    'default': [\n",
    "        \"Question: {q} Answer: {o}\",\n",
    "        \"{q} The answer is {o}\",\n",
    "        \"Q: {q} A: {o}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "def get_question_type(question):\n",
    "    \"\"\"ì§ˆë¬¸ ìœ í˜• ìë™ ë¶„ë¥˜\"\"\"\n",
    "    q = question.lower()\n",
    "    if 'what is' in q or 'what are' in q:\n",
    "        return 'what_is'\n",
    "    elif 'what might' in q or 'what likely' in q:\n",
    "        return 'what_might'\n",
    "    elif 'why' in q:\n",
    "        return 'why'\n",
    "    else:\n",
    "        return 'default'\n",
    "\n",
    "@torch.no_grad()\n",
    "def adaptive_tf_score(img, question, option):\n",
    "    \"\"\"ì§ˆë¬¸ ìœ í˜•ë³„ ì ì‘ì  Teacher Forcing\"\"\"\n",
    "    q_type = get_question_type(question)\n",
    "    templates = PROMPT_TEMPLATES[q_type]\n",
    "    weights = [0.5, 0.3, 0.2]  # í…œí”Œë¦¿ë³„ ê°€ì¤‘ì¹˜\n",
    "    \n",
    "    total_score = 0.0\n",
    "    for template, weight in zip(templates, weights):\n",
    "        prompt = template.format(q=question, o=option)\n",
    "        inp = proc_blip(images=img, text=prompt, return_tensors=\"pt\").to(DEVICE)\n",
    "        loss = blip_vqa(**inp, labels=inp[\"input_ids\"]).loss.item()\n",
    "        total_score += weight * (-loss)\n",
    "    \n",
    "    return total_score\n",
    "\n",
    "@torch.no_grad()\n",
    "def enhanced_clip_score(img, question, option):\n",
    "    \"\"\"ê¸¸ì´ ë³´ì • + ì˜ë¯¸ì  ê°€ì¤‘ì¹˜ CLIP ì ìˆ˜\"\"\"\n",
    "    # ê¸°ë³¸ í…ìŠ¤íŠ¸\n",
    "    text = f\"{question} {option}\"\n",
    "    \n",
    "    img_tensor = clip_pre(img).unsqueeze(0).to(DEVICE)\n",
    "    txt_tensor = clip_tokenizer([text]).to(DEVICE)\n",
    "    \n",
    "    img_feat = clip_model.encode_image(img_tensor)\n",
    "    txt_feat = clip_model.encode_text(txt_tensor)\n",
    "    \n",
    "    img_feat = F.normalize(img_feat, dim=-1)\n",
    "    txt_feat = F.normalize(txt_feat, dim=-1)\n",
    "    \n",
    "    cosine_sim = (img_feat @ txt_feat.T).item()\n",
    "    \n",
    "    # ê¸¸ì´ ë³´ì • (ë„ˆë¬´ ì§§ì€ ë‹µë³€ì— í˜ë„í‹°)\n",
    "    length_penalty = min(1.0, len(option.split()) / 3.0)\n",
    "    \n",
    "    return cosine_sim * length_penalty\n",
    "\n",
    "@torch.no_grad()\n",
    "def multi_generation_score(img, question, option, n_samples=3):\n",
    "    \"\"\"ë‹¤ì¤‘ ìƒì„± + RapidFuzz ìœ ì‚¬ë„\"\"\"\n",
    "    inp = proc_blip(images=img, text=question, return_tensors=\"pt\").to(DEVICE)\n",
    "    \n",
    "    similarities = []\n",
    "    for _ in range(n_samples):\n",
    "        generated_ids = blip_vqa.generate(\n",
    "            **inp,\n",
    "            max_new_tokens=10,\n",
    "            num_beams=3,\n",
    "            temperature=0.7,\n",
    "            do_sample=True\n",
    "        )\n",
    "        \n",
    "        generated_text = proc_blip.decode(generated_ids[0], skip_special_tokens=True)\n",
    "        clean_generated = clean(generated_text.replace(question.lower(), \"\"))\n",
    "        clean_option = clean(option)\n",
    "        \n",
    "        # ë‹¤ì–‘í•œ RapidFuzz ìœ ì‚¬ë„ ë©”íŠ¸ë¦­ ì¡°í•©\n",
    "        ratio_sim = fuzz.ratio(clean_generated, clean_option) / 100.0\n",
    "        partial_sim = fuzz.partial_ratio(clean_generated, clean_option) / 100.0  \n",
    "        token_sim = fuzz.token_sort_ratio(clean_generated, clean_option) / 100.0\n",
    "        \n",
    "        # ê°€ì¤‘ í‰ê· \n",
    "        combined_sim = 0.4 * ratio_sim + 0.3 * partial_sim + 0.3 * token_sim\n",
    "        similarities.append(combined_sim)\n",
    "    \n",
    "    return float(np.mean(similarities))\n",
    "\n",
    "print(\"âœ… ì‚¼ì„± ì±Œë¦°ì§€ íŠ¹í™” ì ìˆ˜ í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2be51e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ìŠ¤ë§ˆíŠ¸ ì ìˆ˜ ì •ê·œí™” ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# ì…€ 5: ì ìˆ˜ ì •ê·œí™” ì‹œìŠ¤í…œ\n",
    "# ===============================\n",
    "\n",
    "class SmartScoreNormalizer:\n",
    "    def __init__(self):\n",
    "        # ì‹¤ì œ ê´€ì¸¡ëœ ì ìˆ˜ ë¶„í¬ ê¸°ë°˜ í†µê³„\n",
    "        self.tf_stats = {'mean': -3.8, 'std': 0.9}\n",
    "        self.clip_stats = {'mean': 0.28, 'std': 0.16}  \n",
    "        self.gen_stats = {'mean': 0.22, 'std': 0.14}\n",
    "    \n",
    "    def normalize_scores(self, tf_score, clip_score, gen_score):\n",
    "        \"\"\"Zì ìˆ˜ ì •ê·œí™” í›„ sigmoidë¡œ 0-1 ë²”ìœ„ ë§¤í•‘\"\"\"\n",
    "        # Z-score ì •ê·œí™”\n",
    "        tf_z = (tf_score - self.tf_stats['mean']) / self.tf_stats['std']\n",
    "        clip_z = (clip_score - self.clip_stats['mean']) / self.clip_stats['std']\n",
    "        gen_z = (gen_score - self.gen_stats['mean']) / self.gen_stats['std']\n",
    "        \n",
    "        # Sigmoid ë³€í™˜ìœ¼ë¡œ 0-1 ë²”ìœ„\n",
    "        tf_norm = 1 / (1 + np.exp(-tf_z))\n",
    "        clip_norm = 1 / (1 + np.exp(-clip_z))\n",
    "        gen_norm = 1 / (1 + np.exp(-gen_z))\n",
    "        \n",
    "        return tf_norm, clip_norm, gen_norm\n",
    "\n",
    "# ì „ì—­ ì •ê·œí™”ê¸° ì´ˆê¸°í™”\n",
    "normalizer = SmartScoreNormalizer()\n",
    "print(\"âœ… ìŠ¤ë§ˆíŠ¸ ì ìˆ˜ ì •ê·œí™” ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c624c4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë™ì  ê°€ì¤‘ì¹˜ ìµœì  ì•™ìƒë¸” ì‹œìŠ¤í…œ ì¤€ë¹„\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# ì…€ 6: ì§ˆë¬¸ ìœ í˜•ë³„ ìµœì  ê°€ì¤‘ì¹˜\n",
    "# ===============================\n",
    "\n",
    "def get_smart_weights(question):\n",
    "    \"\"\"ì§ˆë¬¸ ìœ í˜• ë¶„ì„ ê¸°ë°˜ ìµœì  ê°€ì¤‘ì¹˜ ê²°ì •\"\"\"\n",
    "    q = question.lower()\n",
    "    \n",
    "    # ì„¸ë¶„í™”ëœ ì§ˆë¬¸ ìœ í˜•ë³„ ìµœì  ê°€ì¤‘ì¹˜\n",
    "    if 'what is' in q or 'what are' in q:\n",
    "        return 0.30, 0.55, 0.15  # ê°ì²´ì¸ì‹ â†’ CLIP ìµœìš°ì„ \n",
    "    elif 'why' in q or 'reason' in q:\n",
    "        return 0.70, 0.20, 0.10  # ì¶”ë¡ ì§ˆë¬¸ â†’ TF ìµœìš°ì„ \n",
    "    elif 'what might' in q or 'likely' in q:\n",
    "        return 0.35, 0.30, 0.35  # ì˜ˆì¸¡ì§ˆë¬¸ â†’ GEN ì¤‘ìš”\n",
    "    elif 'where' in q or 'location' in q:\n",
    "        return 0.20, 0.70, 0.10  # ì¥ì†Œì§ˆë¬¸ â†’ CLIP ìµœìš°ì„ \n",
    "    elif 'cultural' in q or 'tradition' in q:\n",
    "        return 0.60, 0.25, 0.15  # ë¬¸í™”ì§ˆë¬¸ â†’ TF ì¤‘ì‹¬\n",
    "    elif 'how' in q:\n",
    "        return 0.50, 0.35, 0.15  # ë°©ë²•ì§ˆë¬¸ â†’ TF ì¤‘ì‹¬\n",
    "    else:\n",
    "        return 0.45, 0.40, 0.15  # ê· í˜•ì¡íŒ ê¸°ë³¸ê°’\n",
    "\n",
    "def optimized_ensemble_scores(img, question, options):\n",
    "    \"\"\"ë™ì  ê°€ì¤‘ì¹˜ + ì •ê·œí™” ìµœì  ì•™ìƒë¸”\"\"\"\n",
    "    w_tf, w_clip, w_gen = get_smart_weights(question)\n",
    "    \n",
    "    scores = []\n",
    "    for opt in options:\n",
    "        # ì›ì‹œ ì ìˆ˜ ê³„ì‚°\n",
    "        tf_raw = adaptive_tf_score(img, question, opt)\n",
    "        clip_raw = enhanced_clip_score(img, question, opt)\n",
    "        gen_raw = multi_generation_score(img, question, opt, n_samples=2)\n",
    "        \n",
    "        # ì ìˆ˜ ì •ê·œí™” ì ìš©\n",
    "        tf_norm, clip_norm, gen_norm = normalizer.normalize_scores(tf_raw, clip_raw, gen_raw)\n",
    "        \n",
    "        # ë™ì  ê°€ì¤‘ ê²°í•©\n",
    "        final_score = w_tf * tf_norm + w_clip * clip_norm + w_gen * gen_norm\n",
    "        scores.append(final_score)\n",
    "    \n",
    "    return scores\n",
    "\n",
    "print(\"âœ… ë™ì  ê°€ì¤‘ì¹˜ ìµœì  ì•™ìƒë¸” ì‹œìŠ¤í…œ ì¤€ë¹„\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f3584f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í–¥ìƒëœ TTA ì•™ìƒë¸” ì¤€ë¹„ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ì…€ 7: í–¥ìƒëœ TTA ì•™ìƒë¸” ì‹œìŠ¤í…œ\n",
    "from PIL import ImageEnhance\n",
    "\n",
    "def enhanced_tta_scores(img, question, options, transforms=None):\n",
    "    if transforms is None:\n",
    "        from torchvision import transforms as T\n",
    "        transforms = [\n",
    "            T.Resize((224,224)),\n",
    "            T.Compose([T.Resize(256), T.CenterCrop(224)]),\n",
    "            T.Compose([T.Resize(256), T.RandomCrop(224)]),\n",
    "            T.ColorJitter(brightness=0.15, contrast=0.15)\n",
    "        ]\n",
    "    all_scores, confs = [], []\n",
    "    for tfm in transforms:\n",
    "        aug = tfm(img) if hasattr(tfm, '__call__') else img\n",
    "        sc = optimized_ensemble_scores(aug, question, options)\n",
    "        conf = max(sc) - np.mean(sc)\n",
    "        all_scores.append(sc)\n",
    "        confs.append(max(conf, 0.1))\n",
    "    total_conf = sum(confs)\n",
    "    weights = [c/total_conf for c in confs]\n",
    "    final = [sum(w*s[i] for w,s in zip(weights, all_scores)) for i in range(len(options))]\n",
    "    return final, weights\n",
    "\n",
    "print(\"âœ… í–¥ìƒëœ TTA ì•™ìƒë¸” ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e04b0667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì˜¨ë„ ìŠ¤ì¼€ì¼ë§ + Softmax ì¤€ë¹„ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ì…€ 8: ì˜¨ë„ ìŠ¤ì¼€ì¼ë§ + Softmax í™•ë¥ í™” í•¨ìˆ˜\n",
    "import numpy as np\n",
    "\n",
    "def temperature_softmax(scores, temperature=1.2):\n",
    "    arr = np.array(scores) / temperature\n",
    "    ex = np.exp(arr - np.max(arr))\n",
    "    return (ex / ex.sum()).tolist()\n",
    "\n",
    "print(\"âœ… ì˜¨ë„ ìŠ¤ì¼€ì¼ë§ + Softmax ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4571096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c142d87d7d564da7a7289f6e07f052f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ğŸ”¥ ìµœì¢… ëŒíŒŒ:   0%|          | 0/852 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ìƒ˜í”Œ 1 ---\n",
      "TTA weights: ['0.25', '0.25', '0.25', '0.25']\n",
      "Raw scores: ['0.1918', '0.2176', '0.2035', '0.1969']\n",
      "Probabilities: ['0.248', '0.253', '0.250', '0.249']\n",
      "ì„ íƒ: B\n",
      "\n",
      "--- ìƒ˜í”Œ 2 ---\n",
      "TTA weights: ['0.25', '0.25', '0.25', '0.25']\n",
      "Raw scores: ['0.2178', '0.1564', '0.1707', '0.1782']\n",
      "Probabilities: ['0.258', '0.245', '0.248', '0.249']\n",
      "ì„ íƒ: A\n",
      "\n",
      "--- ìƒ˜í”Œ 3 ---\n",
      "TTA weights: ['0.25', '0.25', '0.25', '0.25']\n",
      "Raw scores: ['0.1970', '0.2339', '0.2167', '0.2196']\n",
      "Probabilities: ['0.246', '0.254', '0.250', '0.251']\n",
      "ì„ íƒ: B\n",
      "\n",
      "--- ìƒ˜í”Œ 4 ---\n",
      "TTA weights: ['0.25', '0.25', '0.25', '0.25']\n",
      "Raw scores: ['0.1549', '0.1509', '0.1726', '0.1571']\n",
      "Probabilities: ['0.249', '0.248', '0.253', '0.250']\n",
      "ì„ íƒ: C\n",
      "\n",
      "--- ìƒ˜í”Œ 5 ---\n",
      "TTA weights: ['0.25', '0.25', '0.25', '0.25']\n",
      "Raw scores: ['0.1692', '0.1699', '0.1652', '0.1692']\n",
      "Probabilities: ['0.250', '0.250', '0.249', '0.250']\n",
      "ì„ íƒ: B\n",
      "âœ… ìµœì¢… ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ì…€ 9: ë©”íƒ€ ì•™ìƒë¸” + ìµœì¢… ì¶”ë¡  ì‹œìŠ¤í…œ\n",
    "def final_samsung_inference(debug_samples=5, temperature=1.2):\n",
    "    df = pd.read_csv(TEST_CSV)\n",
    "    answers = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"ğŸ”¥ ìµœì¢… ëŒíŒŒ\"):\n",
    "        img_path = os.path.join(IMG_DIR, os.path.basename(row[\"img_path\"]))\n",
    "        if not os.path.exists(img_path):\n",
    "            answers.append(\"A\"); continue\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        q, opts = row[\"Question\"], [row[k] for k in \"ABCD\"]\n",
    "        # 1) Enhanced TTA ì•™ìƒë¸”\n",
    "        tta_scores, tta_w = enhanced_tta_scores(img, q, opts)\n",
    "        # 2) ì˜¨ë„ ìŠ¤ì¼€ì¼ë§ Softmax\n",
    "        prob = temperature_softmax(tta_scores, temperature)\n",
    "        # 3) ìµœì¢… ì„ íƒ\n",
    "        pred = \"ABCD\"[int(np.argmax(prob))]\n",
    "        answers.append(pred)\n",
    "        if idx < debug_samples:\n",
    "            print(f\"\\n--- ìƒ˜í”Œ {idx+1} ---\")\n",
    "            print(f\"TTA weights: {[f'{w:.2f}' for w in tta_w]}\")\n",
    "            print(f\"Raw scores: {[f'{s:.4f}' for s in tta_scores]}\")\n",
    "            print(f\"Probabilities: {[f'{p:.3f}' for p in prob]}\")\n",
    "            print(f\"ì„ íƒ: {pred}\")\n",
    "    sub = pd.read_csv(SUB_CSV)\n",
    "    sub[\"answer\"] = answers\n",
    "    sub.to_csv(SUB_CSV, index=False)\n",
    "    print(\"âœ… ìµœì¢… ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ\")\n",
    "    return answers\n",
    "\n",
    "# ğŸš€ ì‹¤í–‰\n",
    "final_results = final_samsung_inference(debug_samples=5, temperature=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42493c61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2025_Samsung_AI_Challenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
