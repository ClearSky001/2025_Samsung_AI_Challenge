{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# BLIP Fine-tuning Quick Start (Jupyter Version)\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì—ì„œ BLIP fine-tuningì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… PyTorch ë²„ì „: 2.7.1+cu126\n",
            "âœ… CUDA ì‚¬ìš© ê°€ëŠ¥: True\n",
            "âœ… GPU ì´ë¦„: NVIDIA GeForce RTX 4080 Laptop GPU\n",
            "âœ… Transformers ë²„ì „: 4.53.1\n",
            "âœ… WandB ë²„ì „: 0.21.0\n"
          ]
        }
      ],
      "source": [
        "# í™˜ê²½ í™•ì¸\n",
        "import torch\n",
        "import transformers\n",
        "import wandb\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "print(\"âœ… PyTorch ë²„ì „:\", torch.__version__)\n",
        "print(\"âœ… CUDA ì‚¬ìš© ê°€ëŠ¥:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"âœ… GPU ì´ë¦„:\", torch.cuda.get_device_name(0))\n",
        "print(\"âœ… Transformers ë²„ì „:\", transformers.__version__)\n",
        "print(\"âœ… WandB ë²„ì „:\", wandb.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì „ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.\n",
            "  - í•™ìŠµ ë°ì´í„°: dataset/VQAv2/train.json\n",
            "  - ê²€ì¦ ë°ì´í„°: dataset/VQAv2/val.json\n"
          ]
        }
      ],
      "source": [
        "# ë°ì´í„° í™•ì¸\n",
        "train_file = \"dataset/VQAv2/train.json\"\n",
        "val_file = \"dataset/VQAv2/val.json\"\n",
        "\n",
        "if os.path.exists(train_file) and os.path.exists(val_file):\n",
        "    print(\"âœ… ì „ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.\")\n",
        "    print(f\"  - í•™ìŠµ ë°ì´í„°: {train_file}\")\n",
        "    print(f\"  - ê²€ì¦ ë°ì´í„°: {val_file}\")\n",
        "else:\n",
        "    print(\"âŒ ì „ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "    print(\"ë¨¼ì € preprocess_vqav2.pyë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ì‹¤í–‰ ì˜µì…˜ ì„ íƒ\n",
        "\n",
        "ì•„ë˜ ì…€ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•´ì„œ ì‹¤í–‰í•˜ì„¸ìš”:\n",
        "- **ë¹ ë¥¸ í…ŒìŠ¤íŠ¸**: 100ê°œ ìƒ˜í”Œë¡œ 1 ì—í¬í¬ (5-10ë¶„)\n",
        "- **ë‹¨ì¼ ì‹¤í—˜**: 1000ê°œ ìƒ˜í”Œë¡œ 3 ì—í¬í¬ (20-30ë¶„)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\n",
            "ì†Œê·œëª¨ ë°ì´í„°ì…‹ìœ¼ë¡œ 1 ì—í¬í¬ í•™ìŠµì„ ì‹¤í–‰í•©ë‹ˆë‹¤.\n",
            "ì‹¤í–‰ ëª…ë ¹ì–´: c:\\Users\\Lenovo\\anaconda3\\envs\\2025_Samsung_AI_Challenge\\python.exe blip_finetune.py --max_train_samples 100 --max_val_samples 50 --num_train_epochs 1 --per_device_train_batch_size 4 --per_device_eval_batch_size 4 --learning_rate 2e-5 --logging_steps 5 --wandb_name quick-test-jupyter --output_dir ./quick-test-output\n",
            "wandb: Currently logged in as: unknownlimitless0301 (unknownlimitless0301-university-of-suwon6591) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
            "wandb: Tracking run with wandb version 0.21.0\n",
            "wandb: Run data is saved locally in c:\\Users\\Lenovo\\Study\\2025_Samsung_AI_Challenge\\wandb\\run-20250720_205845-tav4fgdg\n",
            "wandb: Run `wandb offline` to turn off syncing.\n",
            "wandb: Syncing run quick-test-jupyter\n",
            "wandb:  View project at https://wandb.ai/unknownlimitless0301-university-of-suwon6591/blip-vqav2-finetuning\n",
            "wandb:  View run at https://wandb.ai/unknownlimitless0301-university-of-suwon6591/blip-vqav2-finetuning/runs/tav4fgdg\n",
            "Using device: cuda\n",
            "Loading processor and model: Salesforce/blip-vqa-capfilt-large\n",
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
            "Loading datasets...\n",
            "Loaded 443757 samples from dataset/VQAv2/train.json\n",
            "Loaded 214354 samples from dataset/VQAv2/val.json\n",
            "Limited training samples to 100\n",
            "Limited validation samples to 50\n",
            "Starting training...\n",
            "\n",
            "0%|          | 0/25 [00:00<?, ?it/s]We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "\n",
            "4%|â–         | 1/25 [00:00<00:22,  1.08it/s]\n",
            "8%|â–Š         | 2/25 [00:01<00:14,  1.56it/s]\n",
            "12%|â–ˆâ–        | 3/25 [00:07<01:10,  3.21s/it]\n",
            "16%|â–ˆâ–Œ        | 4/25 [00:08<00:46,  2.24s/it]\n",
            "20%|â–ˆâ–ˆ        | 5/25 [00:09<00:35,  1.75s/it]\n",
            "\n",
            "{'loss': 10.4623, 'grad_norm': 8.57325267791748, 'learning_rate': 1.9090909090909094e-05, 'epoch': 0.2}\n",
            "\n",
            "20%|â–ˆâ–ˆ        | 5/25 [00:09<00:35,  1.75s/it]\n",
            "24%|â–ˆâ–ˆâ–       | 6/25 [00:10<00:30,  1.62s/it]\n",
            "28%|â–ˆâ–ˆâ–Š       | 7/25 [00:11<00:24,  1.36s/it]\n",
            "32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:12<00:19,  1.16s/it]\n",
            "36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:12<00:16,  1.02s/it]\n",
            "40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:13<00:14,  1.03it/s]\n",
            "\n",
            "{'loss': 9.9127, 'grad_norm': 8.43689250946045, 'learning_rate': 1.4545454545454546e-05, 'epoch': 0.4}\n",
            "\n",
            "40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:14<00:14,  1.03it/s]\n",
            "44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:14<00:12,  1.10it/s]\n",
            "48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:15<00:10,  1.20it/s]\n",
            "52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:15<00:09,  1.28it/s]\n",
            "56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:16<00:08,  1.25it/s]\n",
            "60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:17<00:07,  1.28it/s]\n",
            "\n",
            "{'loss': 9.8951, 'grad_norm': 8.458779335021973, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
            "\n",
            "60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:17<00:07,  1.28it/s]\n",
            "64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:18<00:07,  1.22it/s]\n",
            "68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:19<00:06,  1.25it/s]\n",
            "72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:19<00:05,  1.28it/s]\n",
            "76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:20<00:04,  1.31it/s]\n",
            "80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:21<00:03,  1.36it/s]\n",
            "\n",
            "{'loss': 9.783, 'grad_norm': 8.41150188446045, 'learning_rate': 5.4545454545454545e-06, 'epoch': 0.8}\n",
            "\n",
            "80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:21<00:03,  1.36it/s]\n",
            "84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:21<00:02,  1.41it/s]\n",
            "88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:22<00:02,  1.42it/s]\n",
            "92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:23<00:01,  1.44it/s]\n",
            "96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:24<00:00,  1.40it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:24<00:00,  1.34it/s]\n",
            "\n",
            "{'loss': 9.8694, 'grad_norm': 8.512177467346191, 'learning_rate': 9.090909090909091e-07, 'epoch': 1.0}\n",
            "\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:25<00:00,  1.34it/s]\n",
            "\n",
            "0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "15%|â–ˆâ–Œ        | 2/13 [00:00<00:01,  9.94it/s]\u001b[A\n",
            "\n",
            "23%|â–ˆâ–ˆâ–       | 3/13 [00:00<00:01,  7.66it/s]\u001b[A\n",
            "\n",
            "31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:01,  6.41it/s]\u001b[A\n",
            "\n",
            "38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:00<00:01,  6.06it/s]\u001b[A\n",
            "\n",
            "46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:01,  5.66it/s]\u001b[A\n",
            "\n",
            "54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:01<00:01,  5.54it/s]\u001b[A\n",
            "\n",
            "62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:01<00:00,  5.29it/s]\u001b[A\n",
            "\n",
            "69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:01<00:00,  4.92it/s]\u001b[A\n",
            "\n",
            "77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:01<00:00,  4.81it/s]\u001b[A\n",
            "\n",
            "85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:02<00:00,  4.78it/s]\u001b[A\n",
            "\n",
            "92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:02<00:00,  4.98it/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A{'eval_samples': 2, 'eval_loss': 9.846839904785156, 'eval_runtime': 2.5539, 'eval_samples_per_second': 19.578, 'eval_steps_per_second': 5.09, 'epoch': 1.0}\n",
            "\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:27<00:00,  1.34it/s]\n",
            "\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  4.98it/s]\u001b[A\n",
            "There were missing keys in the checkpoint model loaded: ['text_decoder.cls.predictions.decoder.bias'].\n",
            "\n",
            "\n",
            "{'train_runtime': 31.2987, 'train_samples_per_second': 3.195, 'train_steps_per_second': 0.799, 'train_loss': 9.984495086669922, 'epoch': 1.0}\n",
            "\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:31<00:00,  1.34it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:31<00:00,  1.25s/it]\n",
            "Saving final model...\n",
            "Running final evaluation...\n",
            "\n",
            "0%|          | 0/13 [00:00<?, ?it/s]\n",
            "15%|â–ˆâ–Œ        | 2/13 [00:00<00:01, 10.88it/s]\n",
            "31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:01,  6.70it/s]\n",
            "38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:00<00:01,  6.03it/s]\n",
            "46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:01,  5.75it/s]\n",
            "54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:01<00:01,  5.69it/s]\n",
            "62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:01<00:00,  5.45it/s]\n",
            "69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:01<00:00,  5.53it/s]\n",
            "77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:01<00:00,  5.37it/s]\n",
            "85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:01<00:00,  5.16it/s]\n",
            "92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:02<00:00,  5.26it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  5.90it/s]\n",
            "Final evaluation results: {'eval_samples': 2, 'eval_loss': 9.846839904785156, 'eval_runtime': 2.5996, 'eval_samples_per_second': 19.234, 'eval_steps_per_second': 5.001, 'epoch': 1.0}\n",
            "wandb: Adding directory to artifact (.\\quick-test-output)... Done. 4.8s\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading summary, console lines 12-23\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg; uploading data\n",
            "wandb: uploading artifact blip-vqa-model-tav4fgdg\n",
            "wandb: uploading data\n",
            "wandb:\n",
            "wandb:\n",
            "wandb: Run history:\n",
            "wandb:               eval/loss â–â–\n",
            "wandb:            eval/runtime â–â–ˆ\n",
            "wandb:            eval/samples â–â–\n",
            "wandb: eval/samples_per_second â–ˆâ–\n",
            "wandb:   eval/steps_per_second â–ˆâ–\n",
            "wandb:         final_eval_loss â–\n",
            "wandb:             train/epoch â–â–ƒâ–…â–†â–ˆâ–ˆâ–ˆâ–ˆ\n",
            "wandb:       train/global_step â–â–ƒâ–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "wandb:         train/grad_norm â–ˆâ–‚â–ƒâ–â–…\n",
            "wandb:     train/learning_rate â–ˆâ–†â–…â–ƒâ–\n",
            "wandb:              train/loss â–ˆâ–‚â–‚â–â–‚\n",
            "wandb:\n",
            "wandb: Run summary:\n",
            "wandb:                eval/loss 9.84684\n",
            "wandb:             eval/runtime 2.5996\n",
            "wandb:             eval/samples 2\n",
            "wandb:  eval/samples_per_second 19.234\n",
            "wandb:    eval/steps_per_second 5.001\n",
            "wandb:          final_eval_loss 9.84684\n",
            "wandb:               total_flos 103526791987200.0\n",
            "wandb:              train/epoch 1\n",
            "wandb:        train/global_step 25\n",
            "wandb:          train/grad_norm 8.51218\n",
            "wandb:      train/learning_rate 0.0\n",
            "wandb:               train/loss 9.8694\n",
            "wandb:               train_loss 9.9845\n",
            "wandb:            train_runtime 31.2987\n",
            "wandb: train_samples_per_second 3.195\n",
            "wandb:   train_steps_per_second 0.799\n",
            "wandb:\n",
            "wandb:  View run quick-test-jupyter at: https://wandb.ai/unknownlimitless0301-university-of-suwon6591/blip-vqav2-finetuning/runs/tav4fgdg\n",
            "wandb:  View project at: https://wandb.ai/unknownlimitless0301-university-of-suwon6591/blip-vqav2-finetuning\n",
            "wandb: Synced 5 W&B file(s), 0 media file(s), 18 artifact file(s) and 0 other file(s)\n",
            "wandb: Find logs at: .\\wandb\\run-20250720_205845-tav4fgdg\\logs\n",
            "Training completed!\n",
            "âœ… ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n"
          ]
        }
      ],
      "source": [
        "# ì˜µì…˜ 1: ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (100 ìƒ˜í”Œ, 1 ì—í¬í¬)\n",
        "print(\"ğŸš€ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
        "print(\"ì†Œê·œëª¨ ë°ì´í„°ì…‹ìœ¼ë¡œ 1 ì—í¬í¬ í•™ìŠµì„ ì‹¤í–‰í•©ë‹ˆë‹¤.\")\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "cmd = [\n",
        "    sys.executable, \"blip_finetune.py\",\n",
        "    \"--max_train_samples\", \"100\",\n",
        "    \"--max_val_samples\", \"50\", \n",
        "    \"--num_train_epochs\", \"1\",\n",
        "    \"--per_device_train_batch_size\", \"4\",\n",
        "    \"--per_device_eval_batch_size\", \"4\",\n",
        "    \"--learning_rate\", \"2e-5\",\n",
        "    \"--logging_steps\", \"5\",\n",
        "    \"--wandb_name\", \"quick-test-jupyter\",\n",
        "    \"--output_dir\", \"./quick-test-output\"\n",
        "]\n",
        "\n",
        "print(f\"ì‹¤í–‰ ëª…ë ¹ì–´: {' '.join(cmd)}\")\n",
        "\n",
        "# ì‹¤í–‰ (ì‹¤ì‹œê°„ ì¶œë ¥)\n",
        "process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, \n",
        "                          universal_newlines=True, bufsize=1)\n",
        "\n",
        "for line in process.stdout:\n",
        "    print(line.strip())\n",
        "\n",
        "process.wait()\n",
        "\n",
        "if process.returncode == 0:\n",
        "    print(\"âœ… ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
        "else:\n",
        "    print(f\"âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. Return code: {process.returncode}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì˜µì…˜ 2: ë‹¨ì¼ ì‹¤í—˜ (1000 ìƒ˜í”Œ, 3 ì—í¬í¬)\n",
        "print(\"ğŸ”¥ ë‹¨ì¼ ì‹¤í—˜ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
        "print(\"ì¤‘ê°„ ê·œëª¨ ë°ì´í„°ì…‹ìœ¼ë¡œ 3 ì—í¬í¬ í•™ìŠµì„ ì‹¤í–‰í•©ë‹ˆë‹¤.\")\n",
        "\n",
        "cmd = [\n",
        "    sys.executable, \"blip_finetune.py\",\n",
        "    \"--max_train_samples\", \"1000\",\n",
        "    \"--max_val_samples\", \"500\",\n",
        "    \"--num_train_epochs\", \"3\", \n",
        "    \"--per_device_train_batch_size\", \"8\",\n",
        "    \"--per_device_eval_batch_size\", \"8\",\n",
        "    \"--learning_rate\", \"2e-5\",\n",
        "    \"--wandb_name\", \"single-experiment-jupyter\"\n",
        "]\n",
        "\n",
        "print(f\"ì‹¤í–‰ ëª…ë ¹ì–´: {' '.join(cmd)}\")\n",
        "\n",
        "# ì‹¤í–‰ (ì‹¤ì‹œê°„ ì¶œë ¥)\n",
        "process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, \n",
        "                          universal_newlines=True, bufsize=1)\n",
        "\n",
        "for line in process.stdout:\n",
        "    print(line.strip())\n",
        "\n",
        "process.wait()\n",
        "\n",
        "if process.returncode == 0:\n",
        "    print(\"âœ… ë‹¨ì¼ ì‹¤í—˜ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
        "else:\n",
        "    print(f\"âŒ ì‹¤í—˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. Return code: {process.returncode}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## WandB ê²°ê³¼ í™•ì¸\n",
        "\n",
        "í•™ìŠµì´ ì™„ë£Œë˜ë©´ WandB ëŒ€ì‹œë³´ë“œì—ì„œ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”:\n",
        "- [WandB Dashboard](https://wandb.ai)\n",
        "- í”„ë¡œì íŠ¸: `blip-vqav2-finetuning`\n",
        "- ì‹¤ì‹œê°„ loss, accuracy ê·¸ë˜í”„\n",
        "- GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰\n",
        "- í•™ìŠµë¥  ë³€í™”\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "2025_Samsung_AI_Challenge",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
