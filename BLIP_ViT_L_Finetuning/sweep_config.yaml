program: blip_finetune.py
method: bayes
metric:
  name: eval_loss
  goal: minimize

parameters:
  learning_rate:
    values: [1e-6, 5e-6, 1e-5, 2e-5, 5e-5]
  
  per_device_train_batch_size:
    values: [4, 8, 16]
  
  num_train_epochs:
    values: [2, 3, 4]
  
  weight_decay:
    values: [0.01, 0.05, 0.1]
  
  warmup_steps:
    values: [100, 300, 500, 800, 1000] 