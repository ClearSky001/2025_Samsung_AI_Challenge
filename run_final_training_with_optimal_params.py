#!/usr/bin/env python3
"""
ğŸ† BLIP ìµœì¢… í•™ìŠµ - Optuna ìµœì  íŒŒë¼ë¯¸í„° ìë™ ì ìš©

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” optuna_best_params_final.jsonì—ì„œ ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ 
ìë™ìœ¼ë¡œ ì½ì–´ì™€ì„œ BLIP ëª¨ë¸ì˜ ìµœì¢… í•™ìŠµì„ ì‹¤í–‰í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python run_final_training_with_optimal_params.py [ì˜µì…˜]

ì˜µì…˜:
    --test          í…ŒìŠ¤íŠ¸ í•™ìŠµ (ë¹ ë¥¸ ê²€ì¦ìš©, 5K ìƒ˜í”Œ)
    --full          ì „ì²´ í•™ìŠµ (443K ìƒ˜í”Œ, ê¸°ë³¸ê°’)
    --samples N     ì‚¬ìš©í•  ìƒ˜í”Œ ìˆ˜ ì§€ì •
"""

import os
import sys
import json
import subprocess
import argparse
from datetime import datetime


def load_optimal_params(json_file="optuna_best_params_final.json"):
    """Optuna ìµœì í™” ê²°ê³¼ì—ì„œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¡œë“œ"""
    try:
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        best_params = data['best_params']
        
        print("ğŸ¯ Optuna ìµœì  íŒŒë¼ë¯¸í„° ë¡œë“œ ì™„ë£Œ!")
        print(f"ğŸ“Š ìµœê³  ì„±ëŠ¥ eval_loss: {data['best_eval_loss']:.4f}")
        print(f"ğŸ† ìµœì  Trial ë²ˆí˜¸: {data['best_trial_number']}")
        print(f"â° ìµœì í™” ì™„ë£Œ ì‹œê°„: {data['optimization_time']}")
        print(f"ğŸ“ˆ ì„±ê³µí•œ Trial: {data['successful_trials']}/{data['total_trials']}")
        
        print("\nğŸ”§ ì ìš©í•  í•˜ì´í¼íŒŒë¼ë¯¸í„°:")
        for key, value in best_params.items():
            if key == 'learning_rate':
                print(f"  - {key}: {value:.2e}")
            elif key == 'weight_decay':
                print(f"  - {key}: {value:.4f}")
            else:
                print(f"  - {key}: {value}")
                
        # warmup_ratio ê³„ì‚°
        warmup_ratio = best_params['warmup_steps'] / 2000
        best_params['warmup_ratio'] = warmup_ratio
        
        print(f"  - warmup_ratio: {warmup_ratio:.3f} (warmup_steps {best_params['warmup_steps']}ì—ì„œ ê³„ì‚°)")
        
        return best_params, data
        
    except FileNotFoundError:
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {json_file}")
        print("ğŸ“‹ ë¨¼ì € í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ ì™„ë£Œí•˜ì„¸ìš”.")
        return None, None
    except Exception as e:
        print(f"âŒ íŒŒë¼ë¯¸í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None, None


def run_training(optimal_params, train_samples=None, val_samples=None, test_mode=False):
    """ìµœì  íŒŒë¼ë¯¸í„°ë¡œ BLIP ëª¨ë¸ í•™ìŠµ ì‹¤í–‰"""
    
    # í•™ìŠµ ëª¨ë“œ ì„¤ì •
    if test_mode:
        train_samples = train_samples or 5000
        val_samples = val_samples or 2000
        output_dir = "./blip_test_optimal_model"
        print("ğŸ§ª í…ŒìŠ¤íŠ¸ í•™ìŠµ ëª¨ë“œ")
        print(f"ğŸ“Š í•™ìŠµ ìƒ˜í”Œ: {train_samples:,}ê°œ")
        print(f"ğŸ“Š ê²€ì¦ ìƒ˜í”Œ: {val_samples:,}ê°œ")
        print("â° ì˜ˆìƒ ì‹œê°„: 15-30ë¶„")
    else:
        output_dir = "./blip_final_optimal_model"
        print("ğŸ† ì „ì²´ ë°ì´í„°ì…‹ ìµœì¢… í•™ìŠµ ëª¨ë“œ")
        if train_samples:
            print(f"ğŸ“Š í•™ìŠµ ìƒ˜í”Œ: {train_samples:,}ê°œ")
        else:
            print("ğŸ“Š í•™ìŠµ ìƒ˜í”Œ: ì „ì²´ (~443Kê°œ)")
        print("â° ì˜ˆìƒ ì‹œê°„: 3-6ì‹œê°„")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(output_dir, exist_ok=True)
    
    # í•™ìŠµ ëª…ë ¹ì–´ êµ¬ì„±
    cmd = [
        sys.executable,
        "blip_finetune.py",
        "--train_file", "../dataset/VQAv2/train.json",
        "--val_file", "../dataset/VQAv2/val.json",
        "--per_device_train_batch_size", str(optimal_params['batch_size']),
        "--per_device_eval_batch_size", str(optimal_params['batch_size']),
        "--learning_rate", str(optimal_params['learning_rate']),
        "--weight_decay", str(optimal_params['weight_decay']),
        "--warmup_ratio", str(optimal_params['warmup_ratio']),
        "--num_train_epochs", str(optimal_params['num_epochs']),
        "--output_dir", output_dir,
        "--eval_strategy", "epoch",
        "--save_strategy", "epoch",
        "--load_best_model_at_end", "true",
        "--logging_steps", "100",
        "--save_total_limit", "3",
        "--dataloader_num_workers", "4",
        "--remove_unused_columns", "false",
        "--report_to", "none"
    ]
    
    # ìƒ˜í”Œ ìˆ˜ ì œí•œ ì¶”ê°€
    if train_samples:
        cmd.extend(["--max_train_samples", str(train_samples)])
    if val_samples:
        cmd.extend(["--max_val_samples", str(val_samples)])
    
    print(f"\nğŸš€ ì‹¤í–‰ ëª…ë ¹ì–´:")
    print(" ".join(cmd))
    print("\n" + "=" * 70)
    
    # í•™ìŠµ ì‹¤í–‰
    try:
        start_time = datetime.now()
        print(f"â° í•™ìŠµ ì‹œì‘ ì‹œê°„: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        # WandB ë¹„í™œì„±í™”
        env = os.environ.copy()
        env["WANDB_MODE"] = "disabled"
        env["WANDB_DISABLED"] = "true"
        
        result = subprocess.run(
            cmd,
            cwd="./BLIP_ViT_L_Finetuning",
            env=env,
            timeout=36000
        )
        
        end_time = datetime.now()
        runtime = (end_time - start_time).total_seconds()
        
        if result.returncode == 0:
            print(f"\nğŸ‰ í•™ìŠµ ì™„ë£Œ!")
            print(f"â° ì´ í•™ìŠµ ì‹œê°„: {runtime//3600:.0f}ì‹œê°„ {(runtime%3600)//60:.0f}ë¶„")
            print(f"ğŸ“ ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: {output_dir}")
            print("\nğŸ† í•™ìŠµ ì™„ë£Œ! ì´ì œ ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            return True
            
        else:
            print(f"\nâŒ í•™ìŠµ ì‹¤íŒ¨")
            print(f"Return code: {result.returncode}")
            return False
            
    except subprocess.TimeoutExpired:
        print("\nâ° í•™ìŠµ ì‹œê°„ ì´ˆê³¼ (10ì‹œê°„)")
        return False
        
    except Exception as e:
        print(f"\nâŒ í•™ìŠµ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        return False


def main():
    parser = argparse.ArgumentParser(description="BLIP ìµœì¢… í•™ìŠµ - Optuna ìµœì  íŒŒë¼ë¯¸í„° ìë™ ì ìš©")
    parser.add_argument("--test", action="store_true", help="í…ŒìŠ¤íŠ¸ í•™ìŠµ ëª¨ë“œ (ë¹ ë¥¸ ê²€ì¦ìš©)")
    parser.add_argument("--full", action="store_true", help="ì „ì²´ í•™ìŠµ ëª¨ë“œ (ê¸°ë³¸ê°’)")
    parser.add_argument("--samples", type=int, help="ì‚¬ìš©í•  í•™ìŠµ ìƒ˜í”Œ ìˆ˜")
    parser.add_argument("--val_samples", type=int, help="ì‚¬ìš©í•  ê²€ì¦ ìƒ˜í”Œ ìˆ˜")
    
    args = parser.parse_args()
    
    print("ğŸ† BLIP ìµœì¢… í•™ìŠµ - Optuna ìµœì  íŒŒë¼ë¯¸í„° ìë™ ì ìš©!")
    print("=" * 70)
    
    # ìµœì  íŒŒë¼ë¯¸í„° ë¡œë“œ
    optimal_params, optimization_data = load_optimal_params()
    
    if optimal_params is None:
        print("\nâŒ ìµœì  íŒŒë¼ë¯¸í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit(1)
    
    # í•™ìŠµ ëª¨ë“œ ê²°ì •
    test_mode = args.test or (not args.full and args.samples and args.samples < 50000)
    
    if not test_mode and not args.full:
        # ê¸°ë³¸ê°’ì€ ì „ì²´ í•™ìŠµì´ì§€ë§Œ í™•ì¸ ìš”ì²­
        confirm = input("\nì „ì²´ ë°ì´í„°ì…‹ìœ¼ë¡œ ìµœì¢… í•™ìŠµì„ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (yes/no): ")
        if confirm.lower() not in ['yes', 'y', 'ë„¤', 'ã…‡']:
            print("â¸ï¸ í•™ìŠµì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            print("ğŸ’¡ í…ŒìŠ¤íŠ¸ í•™ìŠµì„ ì›í•˜ì‹œë©´ --test ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
            sys.exit(0)
    
    # í•™ìŠµ ì‹¤í–‰
    success = run_training(
        optimal_params=optimal_params,
        train_samples=args.samples,
        val_samples=args.val_samples,
        test_mode=test_mode
    )
    
    if success:
        print("\nğŸ‰ ìµœì¢… í•™ìŠµ ì„±ê³µ!")
        print("ğŸ† ì‚¼ì„± AI ì±Œë¦°ì§€ ì œì¶œ ì¤€ë¹„ ì™„ë£Œ!")
    else:
        print("\nâŒ í•™ìŠµ ì‹¤íŒ¨")
        sys.exit(1)


if __name__ == "__main__":
    main() 